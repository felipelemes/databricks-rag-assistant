---
title: Databricks RAG Study Assistant
emoji: üìö
colorFrom: blue
colorTo: green
sdk: streamlit
sdk_version: 1.47.1 # IMPORTANT: Ensure this matches your streamlit version in requirements.txt
app_file: app.py
pinned: false
---

# üìö Databricks Study Assistant with RAG

## English

### Project Overview

This is an AI-powered Retrieval Augmented Generation (RAG) system designed to act as a specialized study tutor and technical consultant for Azure Databricks documentation. It aims to provide quick, precise, and context-aware answers directly from official Databricks resources, significantly enhancing study efficiency for certifications and streamlining daily technical problem-solving.

This project aims not only to consolidate my learning in Machine Learning and data engineering but also to create a practical and accessible tool for the community.

### Technical Details

* **Objective:** Interactive consultation assistant for Azure Databricks documentation (Data Engineer Associate Certification & professional use).
* **Knowledge Corpus:**
    * Official Databricks Documentation (approx. 17,800 pages, PDF).
    * Official Databricks Knowledge Base (kb.databricks.com, +900 Q&A articles via web scraping).
* **Content Processing:**
    * **Chunking:** Text split into chunks of 1000 characters with 200 characters overlap.
    * **Embeddings:** `all-MiniLM-L6-v2` model (multilingual, for semantic similarity in Portuguese/English).
    * **Vector Database:** FAISS (Facebook AI Similarity Search) for low-latency vector indexing and retrieval.
* **Large Language Model (LLM):** OpenAI GPT-4o (Generates precise, contextualized, and friendly answers, guided by prompt engineering).
* **Interface:** Streamlit (interactive web application).
* **Multilingual Capability:** Supports questions in Portuguese, based on English documentation, and replies in the query's language.

### Setup and Running Locally

1.  **Clone the Repository:**
    ```bash
    git clone [https://github.com/YOUR_GITHUB_USERNAME/databricks-rag-study-assistant.git](https://github.com/YOUR_GITHUB_USERNAME/databricks-rag-study-assistant.git)
    cd databricks-rag-study-assistant
    ```
2.  **Create and Activate Virtual Environment:**
    ```bash
    python -m venv venv
    # Windows
    .\venv\Scripts\activate
    # macOS/Linux
    source venv/bin/activate
    ```
3.  **Install Dependencies:**
    ```bash
    pip install -r requirements.txt
    ```
4.  4.  **Download Databricks Documentation PDF:**
    Download the `azure-databricks.pdf` file (the 17,800-page official documentation) from the link below and place it into the `data/` directory of this project.
    [**Download Azure Databricks Official Documentation PDF (540MB)**](https://drive.google.com/file/d/1AhsUstnfmnvA9vBkPvE5S9GO06gxXa-N/view?usp=sharing)

    *Note: This file is too large to be hosted directly on GitHub, hence the external link.*
    You can also download the latest Azure Databricks documentation directly from the official website. Simply access the link [**HERE**](https://learn.microsoft.com/en-us/azure/databricks/), scroll to the bottom of the page, locate the "Download PDF" button in the lower-left corner, and click it. Make sure to save the file as "azure-databricks.pdf".
5.  **Prepare the Vector Database (PDF):**
    This script processes the PDF and creates the initial FAISS vector database.
    ```bash
    python prepare_data.py
    ```
6.  **Scrape Databricks Knowledge Base Articles:**
    This script scrapes articles from the Databricks KB and saves them as JSONs.
    ```bash
    python scrape_kb.py
    ```
7.  **Update Vector Database with KB Articles:**
    This script integrates the scraped articles into your existing FAISS vector database.
    ```bash
    python update_vector_db_with_kb.py
    ```
8.  **Set OpenAI API Key:**
    Obtain your OpenAI API Key from [platform.openai.com](https://platform.openai.com/api-keys) and set it as an environment variable in your terminal session:
    ```bash
    # Windows (PowerShell)
    $env:OPENAI_API_KEY="YOUR_API_KEY"
    # macOS/Linux
    export OPENAI_API_KEY="YOUR_API_KEY"
    ```
9.  **Run the Streamlit Application:**
    ```bash
    streamlit run app.py
    ```

---

## Portugu√™s

### Vis√£o Geral do Projeto

Este √© um sistema de Gera√ß√£o Aumentada por Recupera√ß√£o (RAG) baseado em IA, projetado para atuar como um tutor de estudos especializado e consultor t√©cnico para a documenta√ß√£o do Azure Databricks. Seu objetivo √© fornecer respostas r√°pidas, precisas e contextualizadas diretamente de recursos oficiais do Databricks, aprimorando significativamente a efici√™ncia do estudo para certifica√ß√µes e simplificando a resolu√ß√£o de problemas t√©cnicos di√°rios.

Este projeto visa n√£o apenas consolidar meu aprendizado em Machine Learning e engenharia de dados, mas tamb√©m criar uma ferramenta pr√°tica e acess√≠vel para a comunidade.

### Detalhes T√©cnicos

* **Objetivo:** Assistente de consulta interativa para documenta√ß√£o do Azure Databricks (Certifica√ß√£o Data Engineer Associate e uso profissional).
* **Corpus de Conhecimento:**
    * Documenta√ß√£o Oficial do Databricks (aprox. 17.800 p√°ginas, PDF).
    * Knowledge Base Oficial do Databricks (kb.databricks.com, +900 artigos de Q&A via web scraping).
* **Processamento de Conte√∫do:**
    * **Chunking:** Texto dividido em peda√ßos (chunks) de 1000 caracteres com 200 caracteres de sobreposi√ß√£o.
    * **Embeddings:** Modelo `all-MiniLM-L6-v2` (multil√≠ngue, para similaridade sem√¢ntica em portugu√™s/ingl√™s).
    * **Banco de Dados Vetorial:** FAISS (Facebook AI Similarity Search) para indexa√ß√£o e recupera√ß√£o de vetores de baixa lat√™ncia.
* **Modelo de Linguagem Grande (LLM):** OpenAI GPT-4o (Gera√ß√£o de respostas precisas, contextualizadas e amig√°veis, guiadas por engenharia de prompt).
* **Interface:** Streamlit (aplica√ß√£o web interativa).
* **Capacidade Multil√≠ngue:** Suporta perguntas em portugu√™s, com base em documenta√ß√£o em ingl√™s, e responde no idioma da consulta.

### Configura√ß√£o e Execu√ß√£o Local

1.  **Clone o Reposit√≥rio:**
    ```bash
    git clone [https://github.com/SEU_USUARIO_GITHUB/databricks-rag-study-assistant.git](https://github.com/SEU_USUARIO_GITHUB/databricks-rag-study-assistant.git)
    cd databricks-rag-study-assistant
    ```
2.  **Crie e Ative o Ambiente Virtual:**
    ```bash
    python -m venv venv
    # Windows
    .\venv\Scripts\activate
    # macOS/Linux
    source venv/bin/activate
    ```
3.  **Instale as Depend√™ncias:**
    ```bash
    pip install -r requirements.txt
    ```
4.  4.  **Baixe a Documenta√ß√£o PDF do Databricks:**
    Baixe o arquivo `azure-databricks.pdf` (a documenta√ß√£o oficial de 17.800 p√°ginas) no link abaixo e coloque-o no diret√≥rio `data/` deste projeto.
    [**Download da Documenta√ß√£o Oficial do Azure Databricks em PDF (540MB)**](https://drive.google.com/file/d/1AhsUstnfmnvA9vBkPvE5S9GO06gxXa-N/view?usp=sharing)
    *Observa√ß√£o: Este arquivo √© muito grande para ser hospedado diretamente no GitHub, por isso o link externo.*
    Voc√™ tamb√©m pode baixar a documenta√ß√£o mais recente do Azure Databricks diretamente no site oficial. Basta acessar o link [**AQUI**](https://learn.microsoft.com/en-us/azure/databricks/), ir at√© o final da p√°gina, no canto inferior esquerdo e clicar em BAIXAR PDF. Certifique de salva-lo como "azure-databricks.pdf" 
5.  **Prepare o Banco de Dados Vetorial (PDF):**
    Este script processa o PDF e cria o banco de dados vetorial FAISS inicial.
    ```bash
    python prepare_data.py
    ```
6.  **Fa√ßa o Web Scraping dos Artigos da Knowledge Base do Databricks:**
    Este script faz o scraping dos artigos da KB do Databricks e os salva como JSONs.
    ```bash
    python scrape_kb.py
    ```
7.  **Atualize o Banco de Dados Vetorial com os Artigos da KB:**
    Este script integra os artigos raspados ao seu banco de dados vetorial FAISS existente.
    ```bash
    python update_vector_db_with_kb.py
    ```
8.  **Defina a Chave da API da OpenAI:**
    Obtenha sua Chave da API da OpenAI em [platform.openai.com](https://platform.openai.com/api-keys) e defina-a como uma vari√°vel de ambiente na sua sess√£o do terminal:
    ```bash
    # Windows (PowerShell)
    $env:OPENAI_API_KEY="SUA_CHAVE_API"
    # macOS/Linux
    export OPENAI_API_KEY="SUA_CHAVE_API"
    ```
9.  **Execute o Aplicativo Streamlit:**
    ```bash
    streamlit run app.py
    ```
